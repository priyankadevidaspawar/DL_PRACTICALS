{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGhNQVh5y4krJOW3TSroPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyankadevidaspawar/DL_PRACTICALS/blob/main/Text_Processing_For_NLP_Doc2Vec_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4g7auVl54mi",
        "outputId": "300d6e82-597f-4e33-d2ed-fe8a1dc08b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Doc2Vec is used for creating document embeddings. It captures the context of entire documents.\""
      ],
      "metadata": {
        "id": "5fqE77a_XifB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenize into sentences and words\")\n",
        "sentences = sent_tokenize(text)\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "print(\"Tokenized sentences:\", tokenized_sentences)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqX5x_K4Xk4r",
        "outputId": "f62bda1f-e4bf-4bb8-c986-c737df818024"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize into sentences and words\n",
            "Tokenized sentences: [['doc2vec', 'is', 'used', 'for', 'creating', 'document', 'embeddings', '.'], ['it', 'captures', 'the', 'context', 'of', 'entire', 'documents', '.']]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prepare tagged documents\")\n",
        "tagged_data = [TaggedDocument(words=words, tags=[str(idx)]) for idx, words in enumerate(tokenized_sentences)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9FLvXDXXpCo",
        "outputId": "5e724014-24d6-4ce4-d242-9fd09e34db91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare tagged documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train the Doc2Vec model\")\n",
        "model = Doc2Vec(vector_size=100, window=5, min_count=1, dm=1, epochs=20)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "print(\"Doc2Vec model trained successfully\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0ddyZmX25W",
        "outputId": "4812a68c-ed46-4a94-c8cb-fc9436b8af32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train the Doc2Vec model\n",
            "Doc2Vec model trained successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Infer document vectors\")\n",
        "doc_vector = model.infer_vector(word_tokenize(\"Doc2Vec is a powerful tool for document embeddings.\"))\n",
        "print(\"Inferred document vector:\", doc_vector)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4iNACH5X7F4",
        "outputId": "fab977fb-2c3f-4115-e47a-92fe5311f36d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer document vectors\n",
            "Inferred document vector: [ 0.00359611  0.00353972  0.00212776 -0.00294717  0.00041332  0.00448132\n",
            "  0.00066404 -0.00279563  0.00186984 -0.00377182  0.00016561  0.00430332\n",
            "  0.00035355  0.00439539  0.00315545  0.00044831 -0.00487178 -0.00144486\n",
            " -0.00452433  0.00040205 -0.0008362   0.00290121  0.00334319 -0.00424713\n",
            " -0.00359224  0.00111356  0.00150454  0.00472305 -0.00019909  0.00137803\n",
            "  0.00487938  0.00322058 -0.00408214 -0.00021516 -0.00389036 -0.0004202\n",
            " -0.00136434 -0.0018597  -0.00293295  0.00296932  0.00086503 -0.00430004\n",
            " -0.00466377 -0.00094264 -0.00434649 -0.00298988  0.00272228  0.00245445\n",
            " -0.00218912 -0.00334299 -0.00240229 -0.0036729  -0.00060535  0.00210101\n",
            " -0.00035421 -0.00386433  0.00069052  0.00191329  0.00253443  0.00366318\n",
            " -0.00256119  0.00334811 -0.00360294  0.00199573  0.00279029 -0.00411111\n",
            "  0.00169076 -0.00454571  0.00246107  0.00061659  0.00095677  0.00365965\n",
            "  0.00326647 -0.0039252   0.00298195  0.00334231  0.00099804 -0.00222514\n",
            " -0.00106535  0.00473627 -0.00135896  0.00363488 -0.00087245  0.00201077\n",
            " -0.00025202  0.00050933  0.00195126  0.00157802  0.00096574 -0.00108203\n",
            " -0.00056485 -0.00015925  0.00215407 -0.0044436  -0.00433213 -0.00432326\n",
            "  0.00234571  0.00318697 -0.0014495  -0.00177983]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HL-WrOtbX_v_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}